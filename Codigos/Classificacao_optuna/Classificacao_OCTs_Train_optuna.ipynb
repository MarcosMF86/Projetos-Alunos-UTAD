{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oc9CViLzJRJ8"
      },
      "source": [
        "*Utilização do modelo Vision Transformers para Classificação de Estágio de Glaucoma\n",
        "\n",
        "*Otimização em busca dos melhores Hiperparâmetros para o classificador\n",
        "\n",
        "*CNNs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZPEyoVd8Pwv"
      },
      "source": [
        "# Dependências"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGTsyeK7a6nT",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#pip install -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghQ0MnR3gu7O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c796de1-88f4-4e9f-a814-4f8b17b4afa7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "# gpu_info = !nvidia-smi\n",
        "# gpu_info = '\\n'.join(gpu_info)\n",
        "# if gpu_info.find('failed') >= 0:\n",
        "#   print('Not connected to a GPU')\n",
        "# else:\n",
        "#   print(gpu_info)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install classification-models-3D --quiet\n",
        "#pip install classification-models-3D\n",
        "!pip install keras_applications --quiet\n",
        "!pip install optuna --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBDGqFpwpkdg",
        "outputId": "5b3b302d-a036-42d6-9345-b69b8f5bf30b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.6/386.6 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "r3A4VA8dv05n"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "#import tensorflow_addons as tfa\n",
        "import glob, warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "from collections import Counter#usar para contar a quantidade de uma classe ex: counter(y_train)\n",
        "import os\n",
        "from google.colab import drive\n",
        "from google.colab import files\n",
        "import keras\n",
        "import zipfile\n",
        "from io import BytesIO\n",
        "\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, GlobalAveragePooling2D, Concatenate, Reshape, GlobalMaxPooling2D, GlobalMaxPooling3D, GlobalAveragePooling3D, Conv2D, Conv1D, Add\n",
        "from keras import regularizers\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "import sklearn\n",
        "from sklearn.metrics import cohen_kappa_score, roc_auc_score, roc_curve,accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import random\n",
        "import cv2\n",
        "import gdown\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow_hub as hub\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow import keras\n",
        "import random\n",
        "import sklearn\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "from tensorflow.keras import layers\n",
        "import csv\n",
        "from scipy import stats\n",
        "from keras.applications.densenet import DenseNet121\n",
        "from keras.applications.densenet import DenseNet169\n",
        "from keras.applications.resnet import ResNet50\n",
        "from keras.applications.resnet import ResNet101\n",
        "from keras.applications.resnet import ResNet152\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.models import Sequential, Model\n",
        "import time\n",
        "from pathlib import Path\n",
        "import gc\n",
        "#from keras.backend import int_shape\n",
        "from tensorflow.keras import backend as K\n",
        "import pickle\n",
        "#from livelossplot import PlotLossesKeras\n",
        "import albumentations as A\n",
        "import optuna\n",
        "from keras.applications.densenet import preprocess_input\n",
        "import json\n",
        "from keras import backend as K\n",
        "from classification_models_3D.tfkeras import Classifiers\n",
        "#keras.__version__\n",
        "warnings.filterwarnings('ignore')\n",
        "from matplotlib import pyplot\n",
        "import sys\n",
        "#print('TensorFlow Version ' + tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#obtendo diretorio da base\n",
        "drive.mount('/content/gdrive',force_remount=True)\n",
        "path_dataset = '/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/multi-modality_images'\n",
        "os.chdir(path_dataset)\n",
        "\n",
        "#Funções Especificas GAMMA\n",
        "from utils_GAMMA import padroniza_resultado\n",
        "from utils_GAMMA import converte"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JjLhnvK72YG",
        "outputId": "cf538532-7e58-4c7e-acec-c89fbb497cea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_LCC90hOA38"
      },
      "source": [
        "# Configuração dos Hiperparâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "x1Dzcr6_OEWH"
      },
      "outputs": [],
      "source": [
        "# DATA\n",
        "# AUGMENTATION\n",
        "def define_hp():#definir hiperparâmetros\n",
        "  IMAGE_SIZE = 128\n",
        "  depth = 64 #Profundidade dos volumes OCTs (Usado na leitura de volumes OCTs)\n",
        "\n",
        "  EPOCHS = 3\n",
        "  early_stop_epochs = 15\n",
        "  learning_rate_epochs = 5\n",
        "  number_of_random_points = 25  # random searches to start opt process\n",
        "  return IMAGE_SIZE, depth, EPOCHS, early_stop_epochs, learning_rate_epochs, number_of_random_points\n",
        "\n",
        "def create_folder_save(dataset):#Criar pastas para salvar modelos treinados e criados pelo processo de otimização\n",
        "  path_to_models = '/content/Modelos Salvos/'\n",
        "  if not Path(path_to_models).is_dir():\n",
        "    os.mkdir(path_to_models)\n",
        "\n",
        "  dir_save = path_to_models + dataset\n",
        "  if not Path(dir_save).is_dir():\n",
        "    os.mkdir(dir_save)\n",
        "  return dir_save\n",
        "\n",
        "def create_folder_results_optuna(dataset):#Criar pastas para salvar dataframe criados pelo processo de otimização\n",
        "  path_to_results_optuna = '/content/Resultados_optuna/'\n",
        "  if not Path(path_to_results_optuna).is_dir():\n",
        "    os.mkdir(path_to_results_optuna)\n",
        "\n",
        "  results_dir = path_to_results_optuna + dataset\n",
        "  if not Path(results_dir).is_dir():\n",
        "    os.mkdir(results_dir)\n",
        "  return results_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sH0qrRfCK2H"
      },
      "source": [
        "# Leitura de OCTs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_dataset_Novas_OCTs = '/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data'"
      ],
      "metadata": {
        "id": "KjEcH_-1R4yN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rl69maz-CKJB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da5e234a-84a5-4aa8-cb96-39e2edabdec7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0001\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0002\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0003\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0004\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0005\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0006\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0007\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0008\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0009\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0010\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0011\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0012\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0013\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0014\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0015\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0016\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0017\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0018\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0019\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0020\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0021\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0022\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0023\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0024\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0025\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0026\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0027\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0028\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0029\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0030\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0031\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0032\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0033\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0034\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0035\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0036\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0037\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0038\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0039\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0040\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0041\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0042\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0043\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0044\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0045\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0046\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0047\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0048\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0049\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0050\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0051\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0052\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0053\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0054\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0055\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0056\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0057\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0058\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0059\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0060\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0061\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0062\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0063\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0064\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0065\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0066\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0067\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0068\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0069\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0070\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0071\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0072\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0073\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0074\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0075\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0076\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0077\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0078\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0079\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0080\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0081\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0082\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0083\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0084\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0085\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0086\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0087\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0088\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0089\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0090\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0091\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0092\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0093\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0094\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0095\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0096\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0097\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0098\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0099\n",
            "/content/gdrive/My Drive/Doutorado/Bases/GAMMA_training_data/Novas Imagens OCT/0100\n"
          ]
        }
      ],
      "source": [
        "# from utils_GAMMA import process_scan\n",
        "# from utils_GAMMA import dir_octs\n",
        "from utils_GAMMA_Novas_OCTS import process_scan\n",
        "from utils_GAMMA_Novas_OCTS import dir_octs\n",
        "#scan_paths = dir_octs(path_dataset,'multi-modality_images',0)#obtem diretorio dos volumes\n",
        "scan_paths = dir_octs(path_dataset_Novas_OCTs,'Novas Imagens OCT',0)#Imagens com recorte\n",
        "#scan_paths = scan_paths[:2]\n",
        "X_oct = np.array([process_scan(path,IMAGE_SIZE, depth) for path in scan_paths])#lê volumes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Novas_OCT_64_128_Train.pkl','wb') as f:#Depth - IMG Size\n",
        "  pickle.dump(X_oct, f)"
      ],
      "metadata": {
        "id": "wQ5F56HKjAGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Carregar OCTs Salvas"
      ],
      "metadata": {
        "id": "T1jUBnNuiqAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "  folder_OCTs_labels = '/content/gdrive/MyDrive/Doutorado/Bases/GAMMA_training_data/multi-modality_images/'\n",
        "  file_octs = 'Novas_OCT_64_128_Train.pkl'\n",
        "  #folder_labels = '/content/gdrive/MyDrive/Doutorado/Bases/GAMMA_training_data/'\n",
        "  file_labels = 'Y_Train.pkl'\n",
        "  #Carregar array\n",
        "  with open(folder_OCTs_labels + file_octs,'rb') as f:\n",
        "    X_train_oct = pickle.load(f)\n",
        "\n",
        "  with open(folder_OCTs_labels + file_labels,'rb') as f:\n",
        "    Y = pickle.load(f)\n",
        "  num_classes = len(np.unique(Y))\n",
        "  return X_train_oct, Y, num_classes"
      ],
      "metadata": {
        "id": "TdBdnkiejPCK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfWV4riR5cOX"
      },
      "source": [
        "# Divide Treino/Validação\n",
        "Usar split de validação fixo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "SqdcH2sue_mY"
      },
      "outputs": [],
      "source": [
        "def split_train_val(X_train_oct, Y):\n",
        "  x_train_oct, x_val_oct, y_train_oct, y_val_oct = train_test_split(X_train_oct, Y, test_size=0.1, random_state=42,stratify=Y)\n",
        "\n",
        "  print(f\"x_train shape: {x_train_oct.shape} - y_train shape: {y_train_oct.shape}\")\n",
        "  print(f\"x_val shape: {x_val_oct.shape} - y_val shape: {y_val_oct.shape}\")\n",
        "  return x_train_oct, x_val_oct, y_train_oct, y_val_oct"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fit Models"
      ],
      "metadata": {
        "id": "IS8d27ks1qX7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_models(number_trial, fine_tuning, model, batch_size,lr, dir_save, x_train_oct, EPOCHS, early_stop_epochs, y_train_oct, x_val_oct, y_val_oct, cnn_model):\n",
        "  # callbacks for early stopping and for learning rate reducer\n",
        "  fn = dir_save + cnn_model + '_' +number_trial + '_cnn.keras'\n",
        "  #fn = dir_save + str(trial.number) + '_cnn.hdf5'#somente pesos\n",
        "  #fn = '/content/Modelos Salvos/' + str(trial.number) + '_cnn.hdf5'#somente pesos\n",
        "\n",
        "\n",
        "  # If already batched\n",
        "  #total_steps = len(train_set)*config['EPOCHS']\n",
        "  # If not batched\n",
        "  #total_steps = len(train_set)/config['BATCH_SIZE']*config['EPOCHS']\n",
        "  total_steps = len(x_train_oct)/batch_size*EPOCHS\n",
        "  # 5% of the steps\n",
        "  warmup_steps = int(0.05*total_steps)\n",
        "\n",
        "  #compile\n",
        "  model.trainable = True\n",
        "  opt = Adam(learning_rate=lr)\n",
        "  #opt = Adam(learning_rate=1e-5)  # default = 0.001 // learning_rate=lr\n",
        "  #model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])#loss='sparse_categorical_crossentropy'\n",
        "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                  optimizer='adam',\n",
        "                  #jit_compile=True,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "  if fine_tuning==1:# 2 etapa de treino. todas as camadas da cnn descongeladas\n",
        "    callbacks_list = [EarlyStopping(monitor='val_loss', patience=early_stop_epochs, verbose=1, mode='auto', restore_best_weights=True),\n",
        "                      #ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=learning_rate_epochs, verbose=0, mode='auto', min_lr=1.0e-6),\n",
        "                      ModelCheckpoint(filepath=fn, monitor='val_loss', verbose=1, save_best_only=True),\n",
        "                      #WarmupCosineDecay(total_steps=total_steps, warmup_steps=warmup_steps, hold=int(warmup_steps/2), start_lr=0.0, target_lr=lr)\n",
        "                      ]\n",
        "  else:#aquecimento\n",
        "    callbacks_list = [EarlyStopping(monitor='val_loss', patience=early_stop_epochs, verbose=1, mode='auto', restore_best_weights=True),\n",
        "                      #ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=learning_rate_epochs, verbose=0, mode='auto', min_lr=1.0e-6),\n",
        "                      ModelCheckpoint(filepath=fn, monitor='val_loss', verbose=1,save_weights_only=False, save_best_only=True)\n",
        "                      ]\n",
        "\n",
        "\n",
        "  # fit the model\n",
        "  h = model.fit(x=x_train_oct, y=y_train_oct,\n",
        "                          batch_size=batch_size,\n",
        "                          epochs=EPOCHS,\n",
        "                          #validation_split=0.1,\n",
        "                          validation_data=(x_val_oct, y_val_oct),\n",
        "                          shuffle=True, verbose=1,\n",
        "                          callbacks=callbacks_list)\n",
        "\n",
        "  if fine_tuning==1:\n",
        "    lrs = callbacks_list[2].lrs#Conjunto de taxas de aprendizado para ser possível plotar o grafico\n",
        "    return h, model, lrs\n",
        "  else:\n",
        "    return h, model"
      ],
      "metadata": {
        "id": "xh8ABiS21sAl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build Model"
      ],
      "metadata": {
        "id": "8L5pxED20OUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(num_dense_nodes, lr, dense_nodes_divisor, batch_size, drop_out_rate, cnn_model, num_layers, depth, IMAGE_SIZE, num_classes):\n",
        "  canais = 3\n",
        "  if cnn_model == 'InceptionV3':\n",
        "    Rede3D, preprocess_input = Classifiers.get('inceptionv3')\n",
        "    model_oct = Rede3D(input_shape=(depth, IMAGE_SIZE, IMAGE_SIZE, 3), weights='imagenet',include_top=False)\n",
        "\n",
        "  if cnn_model == 'VGG19':\n",
        "    Rede3D, preprocess_input = Classifiers.get('vgg19')\n",
        "    model_oct = Rede3D(input_shape=(depth, IMAGE_SIZE, IMAGE_SIZE, 3), weights='imagenet',include_top=False)\n",
        "\n",
        "  if cnn_model == 'resnet50':\n",
        "    #x = tf.keras.applications.resnet50.preprocess_input(x)\n",
        "    Rede3D, preprocess_input = Classifiers.get('resnet50')\n",
        "    model_oct = Rede3D(input_shape=(depth, IMAGE_SIZE, IMAGE_SIZE, 3), weights='imagenet',include_top=False)\n",
        "\n",
        "  if cnn_model == 'resnet101':\n",
        "    Rede3D, preprocess_input = Classifiers.get('resnet101')\n",
        "    model_oct = Rede3D(input_shape=(depth, IMAGE_SIZE, IMAGE_SIZE, 3), weights='imagenet',include_top=False)\n",
        "\n",
        "  if cnn_model == 'resnet152':\n",
        "    Rede3D, preprocess_input = Classifiers.get('resnet152')\n",
        "    model_oct = Rede3D(input_shape=(depth, IMAGE_SIZE, IMAGE_SIZE, 3), weights='imagenet',include_top=False)\n",
        "\n",
        "  if cnn_model == 'Densenet121':\n",
        "    #x = tf.keras.applications.densenet.preprocess_input(x)\n",
        "    Rede3D, preprocess_input = Classifiers.get('densenet121')\n",
        "    model_oct = Rede3D(input_shape=(depth, IMAGE_SIZE, IMAGE_SIZE, 3), weights='imagenet',include_top=False)\n",
        "\n",
        "  if cnn_model == 'Densenet169':\n",
        "    #x = tf.keras.applications.densenet.preprocess_input(x)\n",
        "    Rede3D, preprocess_input = Classifiers.get('densenet121')\n",
        "    model_oct = Rede3D(input_shape=(depth, IMAGE_SIZE, IMAGE_SIZE, 3), weights='imagenet',include_top=False)\n",
        "\n",
        "  x = model_oct.output\n",
        "  x = Flatten()(x)\n",
        "  #MLP\n",
        "  #x = Dense(num_dense_nodes, kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4), activation='relu')(x)#regularazação\n",
        "  x = Dense(num_dense_nodes, activation='relu')(x)\n",
        "  x = Dropout(drop_out_rate)(x)\n",
        "  if num_layers == 2:\n",
        "    #x = Dense(num_dense_nodes//dense_nodes_divisor, kernel_regularizer=regularizers.L1L2(l1=1e-5, l2=1e-4),activation='relu')(x)#regularazação\n",
        "    x = Dense(num_dense_nodes//dense_nodes_divisor, activation='relu')(x)\n",
        "    x = Dropout(drop_out_rate)(x)\n",
        "  output_tensor = Dense(num_classes, activation='softmax')(x)\n",
        "  #Instanciar e compilar modelo\n",
        "  model = Model(inputs=model_oct.input,outputs=output_tensor)\n",
        "  opt = Adam(learning_rate=lr)  # default = 0.001 // learning_rate=lr\n",
        "  model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])#loss='sparse_categorical_crossentropy'\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "4ahJjKAX16C3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4odujajzijHe"
      },
      "source": [
        "# Configuração do Otimizador do classificador OCT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "W48lSRb2inFX"
      },
      "outputs": [],
      "source": [
        "def objective(trial):#cria e avalia modelo\n",
        "  num_dense_nodes = trial.suggest_categorical('num_dense_nodes', [32, 64, 128, 256])\n",
        "  dense_nodes_divisor = trial.suggest_categorical('dense_nodes_divisor',[2, 4, 8])\n",
        "  lr = trial.suggest_categorical('lr', [0.01, 0.001, 0.0001])\n",
        "  batch_size = trial.suggest_categorical('batch_size', [1, 2, 3])\n",
        "  drop_out_rate=trial.suggest_float('drop_out_rate', 0.0, 0.5, step=0.1)\n",
        "  num_layers = trial.suggest_categorical('num_layers',[1,2])\n",
        "  #drop_out=trial.suggest_discrete_uniform('drop_out', 0.05, 0.5, 0.05)\n",
        "  cnn_model = trial.suggest_categorical('cnn_model', ['VGG19', 'resnet50', 'Densenet121', 'Densenet169'])\n",
        "\n",
        "  #Hiperparâmetros\n",
        "  IMAGE_SIZE, depth, EPOCHS, early_stop_epochs, learning_rate_epochs, number_of_random =  define_hp()\n",
        "  dataset = 'GAMMA/'\n",
        "  dir_save = create_folder_save(dataset)#Pastas para salvar Modelos treinados e dataframe oriundo do processo de otimização\n",
        "\n",
        "  X_train_oct, Y, num_classes = load_dataset()#Load oct volumes\n",
        "  x_train_oct, x_val_oct, y_train_oct, y_val_oct = split_train_val(X_train_oct, Y)#Split train/val\n",
        "\n",
        "  #constroi modelo\n",
        "  model = build_model(num_dense_nodes, lr, dense_nodes_divisor, batch_size, drop_out_rate, cnn_model, num_layers, depth, IMAGE_SIZE, num_classes)\n",
        "\n",
        "  print(\"=\"*10, \"Trial\", str(trial.number), \"=\"*10, cnn_model)\n",
        "\n",
        "\n",
        "  #Fine tuning\n",
        "  fine_tuning=0 # (1) - Com cosine decay\n",
        "  # for layer in model.layers:\n",
        "    # print(layer.trainable)\n",
        "  if fine_tuning==1:\n",
        "    h,model,lrs = fit_models(str(trial.number), fine_tuning, model, batch_size,lr, dir_save, x_train_oct, EPOCHS, early_stop_epochs, y_train_oct, x_val_oct, y_val_oct, cnn_model)\n",
        "    plt.plot(lrs)\n",
        "  else:\n",
        "    h,model = fit_models(str(trial.number), fine_tuning, model, batch_size,lr, dir_save, x_train_oct, EPOCHS, early_stop_epochs, y_train_oct, x_val_oct, y_val_oct, cnn_model)\n",
        "\n",
        "  validation_loss = np.min(h.history['val_loss'])\n",
        "  val_acc = np.max(h.history['val_accuracy'])\n",
        "\n",
        "  #save history in json file\n",
        "  history_dict = h.history\n",
        "  history_dir = '/content/history/'\n",
        "\n",
        "  if not Path(history_dir).is_dir():\n",
        "    os.mkdir(history_dir)\n",
        "\n",
        "  out_file=open(history_dir + 'history_json_Trial_' + (str(trial.number)),\"a\")\n",
        "  json.dump(history_dict, out_file)\n",
        "  out_file.close()\n",
        "\n",
        "  #json.dump(history_dict, open(history_path, 'w'))\n",
        "  return validation_loss, val_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bw-Ec_iVizQA"
      },
      "source": [
        "#Otimização"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if not Path(dir_save).is_dir():\n",
        "#   os.mkdir(dir_save)\n",
        "\n",
        "# os.chdir(dir_save)\n",
        "def otimizacao():\n",
        "  optimizer_direction = ['minimize', \"maximize\"]\n",
        "  print('\\n*** starting at',pd.Timestamp.now())\n",
        "  start_time_total = time.time()\n",
        "  optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "  study = optuna.create_study(directions=optimizer_direction,study_name=\"starter-experiment\")\n",
        "  study.optimize(objective, n_trials=1,gc_after_trial=True)\n",
        "  df_results = study.trials_dataframe()\n",
        "  elapsed_time_total = (time.time()-start_time_total)/60\n",
        "  print('\\n\\ntotal elapsed time =',elapsed_time_total,' minutes')\n",
        "  return study, df_results"
      ],
      "metadata": {
        "collapsed": true,
        "id": "C1nYfFWS3Qeg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_results(study, df_results, results_dir):\n",
        "  df = study.trials_dataframe()\n",
        "  df_results.to_csv(results_dir + 'df_optuna_results.csv')\n",
        "  df_results.to_pickle(results_dir + 'df_optuna_results.pkl')"
      ],
      "metadata": {
        "id": "j6FJ3a7U4uqP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sort_results(results_dir):\n",
        "  dataframe = pd.read_csv(results_dir+'df_optuna_results.csv')\n",
        "  dataframe.sort_values(\"values_0\",axis=0,ascending=True, inplace=True, na_position='first')\n",
        "  print(\"Sorted CSV file (according to multiple columns) = \", dataframe.head(10))\n",
        "  return dataframe"
      ],
      "metadata": {
        "id": "Zhl9R-kjDaGW"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_diagnostics(history_no_warm):\n",
        " # plot loss train\n",
        " fig, ax = pyplot.subplots(2,2, figsize=(10,10))\n",
        " fig.tight_layout(pad=2.0)\n",
        " ax[0, 0].title.set_text('Cross Entropy Loss Training')\n",
        " #ax[0, 0].plot(history_warm['loss'], color='blue', label='Trial_8')\n",
        " ax[0, 0].plot(history_no_warm['loss'], color='orange', label='Trial_2')\n",
        " ax[0, 0].legend(loc='best')\n",
        "\n",
        " # plot loss validation\n",
        " ax[0, 1].title.set_text('Cross Entropy Loss Validation')\n",
        " #ax[0, 1].plot(history_warm['val_loss'], color='blue', label='Trial_8')\n",
        " ax[0, 1].plot(history_no_warm['val_loss'], color='orange', label='Trial_2')\n",
        " ax[0, 1].legend(loc='best')\n",
        "\n",
        " # plot accuracy training\n",
        " #pyplot.subplot(212)\n",
        " ax[1, 0].title.set_text('Accuracy Training')\n",
        " #ax[1, 0].plot(history_warm['accuracy'], color='blue', label='Trial_8')\n",
        " ax[1, 0].plot(history_no_warm['accuracy'], color='orange', label='Trial_2')\n",
        " ax[1, 0].legend(loc='best')\n",
        "\n",
        "  # plot acc validation\n",
        " ax[1, 1].title.set_text('Accuracy Validation')\n",
        " #ax[1, 1].plot(history_warm['val_accuracy'], color='blue', label='Trial_8')\n",
        " ax[1, 1].plot(history_no_warm['val_accuracy'], color='orange', label='Trial_2')\n",
        " ax[1, 1].legend(loc='best')"
      ],
      "metadata": {
        "id": "iDxMT1G4F81v"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "  study, df_results = otimizacao()\n",
        "  dataset = 'GAMMA/'\n",
        "  dir_save = create_folder_save(dataset)#Pastas para salvar Modelos treinados e dataframe oriundo do processo de otimização\n",
        "  results_dir = create_folder_results_optuna(dataset)\n",
        "  save_results(study, df_results, results_dir)\n",
        "  dataframe = sort_results(results_dir)\n",
        "  history = json.load(open('/content/history/history_json_Trial_0', 'r'))\n",
        "  summarize_diagnostics(history)"
      ],
      "metadata": {
        "id": "3noCzToD4gt2"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "P1l2iTjO5cKF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6sH0qrRfCK2H",
        "ryFcn3TWSSpx",
        "5B7c3dcoDTsZ"
      ],
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}